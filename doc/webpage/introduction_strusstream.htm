<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<link rel="icon" type="image/ico" href="images/strus.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Strus stream, a library for fast document stream processing for Strus." />
	<meta name="keywords" content="high performance document stream processing pattern matching C++" />
	<meta name="author" content="Patrick Frey &lt;patrickpfrey (a) yahoo (dt) com&gt;" />
	<link rel="stylesheet" type="text/css" href="text-profile.css" title="Text Profile" media="all" />
	<title>Strus Stream</title>
</head>

<body>
<div id="wrap">
<div id="content">
	<h1>Strus Stream</h1>
	<h2>Description</h2>
	<p id="description"><i>StrusStream</i> is an event or dataflow driven pattern detection library for 
	text processing with a competitive performance, suitable for processing large sets of patterns.
	It can be used for detecting multipart entities or structures in text. In a bigger context it can
	support NLP and entity recognition.<br/>
	The current implementation status allows us to detect patterns that are describable as expression 
	trees with basic tokens as leafs. The basic tokens are recognized with regular expressions on text.<br/>
	We are aware that this is only one part of the field, but an important one. But for the support
	of statistical classifiers we have only ideas floating around till now. We are trying to find
	good connectors to existing libraries for maschine learning and to provide the universe for
	processing and storing features for retrieval in this context.
	</p>

	<h2>Justification of the name StrusStream</h2>
	<p id="description">
	The name <i>StrusStream</i> reflects its event or data flow driven processing of text.
	Its programming paradigms borrow from concepts of <a href=https://en.wikipedia.org/wiki/Stream_processing">
	stream processing</a>. But it is not related to modern stream processing frameworks for event
	driven processing. The association to distributed systems (like for example <a href="http://flink.apache.org/">Apache Flink</a>)
	that process streams of huge amount of events with a big flow rate under many different constraints as 
	latency, throughput, fault tolerance and uniqueness guarantees makes the name <i>StrusStream</i> a 
	sort of a misnamer.<br/>
	We just did not find a better name yet.
	</p>

	<h2>The Intel hyperscan library</h3>
	<p id="description"><i>StrusStream</i> uses the <a href="https://01.org/hyperscan">hyperscan</a> library from <i>Intel</i>
	for tokenization.<br/>
	Thanks to <i>Intel</i> for publishing this great work as open source.
	</p>

	<h2>Links to alternative solutions</h2>
	<p id="description">
	The following links show alternatives for pattern detection in documents.
	<ol>
	<li><a href="http://stanfordnlp.github.io/CoreNLP">CoreNLP</a>, a tool suite for different aspects of NLP,
		including <a href="http://nlp.stanford.edu/software/tokensregex.html">pattern matching</a> on text,
		licensed under <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GPLv3</a>. 
		API available for Java. Stanford <i>CoreNLP</i> covers much more than simple pattern
		matching. It provides a workbench for all aspects of natural language processing accompanied
		by a huge knowledge base on the topic.
	</li>
	<li><a href="https://github.com/mit-nlp">https://github.com/mit-nlp</a>
	</li>
	<li>The <a href="https://uima.apache.org/ruta.html">Uima Ruta</a> workbench for rule-based text annotation,
	licensed under the <a href="http://www.apache.org/licenses">Apache license</a>.
	APIs available for Java an C++. With Uima Ruta you get a framework to define arbitrary rules on text with
	its connectors to the big <i>Apache</i> universe for scalable data processing.
	</li>
	</ol>
	</p>

	<h2>How StrusStream works</h2>
	<p id="description">
	<i>StrusStream</i> is completely dataflow driven. It does not detect patterns by an imperative procedure 
	triggered by events in the source data stream. Though it does start the initiation of a pattern
	detection with a key event triggering it.
	But rather than subsequently executing a program, it installs for every pattern node triggered a small set
	of triggers and a slot with an expiration time. Signals are fired to the slot when an event matching
	a trigger occurrs in the subsequent event stream. The completion all awaited signals of a slot leads
	to an emission of a signal for other slots waiting for it and/or the production of a result.<br/>
	This pattern of processing can also be found in other form in event driven stream processing libraries:
	A node waits untils all conditions of a rule all fulfilled and emits an event that is forwarded to another
	node. If a timeout for the rule occurrs, then the rule is discarded.
	</p>

	<h3>Operators</h3>
	<p id="description">
	<i>StrusStream</i> defines patterns as expression trees of nodes. Each node represents a basic token
	in the source or operators on tuples of nodes. Most of the operators supported are named according to the
	<a href="http://www.project-strus.net/builtin_functions.htm">posting join operators</a> in the
	strus query evaluation. Not all of them are implemented though and some exist in <i>StrusStream</i>,
	but not in this form in the query evaluation:
	<h4>Token pattern matching operators</h4>
	<ol>
	<li><b>any</b>: Matches if any of the argument subexpressions or tokens matches.</li>
	<li><b>and</b>: Matches if all of the argument subexpressions or tokens match with the same ordinal position.</li>
	<li><b>sequence</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments within a proximity range of ordinal positions specified.</li>
	<li><b>sequence_imm</b>: <i>imm</i> means immediate. Same as sequence, but the elements have no gaps in between. No gap means that the oridinal position of the follower element in the sequence is the end ordinal position of the predecessor plus 1.</li>
	<li><b>sequence_struct</b>: Matches if the argument subexpressions or tokens appear in the order as the arguments within a proximity range of ordinal positions specified without a structure delimiter (e.g. end of sentence token), specified as first argument, within the span of a match.</li>
	<li><b>within</b>: Matches if the argument subexpressions or tokens appear in arbitrary order within a proximity range of ordinal positions specified.</li>
	<li><b>within_struct</b>: Matches if the argument subexpressions or tokens appear in arbitrary order within a proximity range of ordinal positions specified without a structure delimiter (e.g. end of sentence token), specified as first argument, within the span of a match.</li>
	</ol>
	</p>

	<h2>Example</h2>
	<p id="description">The following example illustrates how <i>StrusStream</i> works.
	</p>
	<h3>Example patterns defined</h3>
	<h4>Define the patterns with in a configuration file</h4>
	<p id="description">We define the example rules defined in the following listing in a file "example.rul".
	The declarations with an identifier followed by a ':' specify the tokens defined by regular expressions. The counting of the different token start positions defines the ordinal positions of the tokens. The number following a '^' after the name of the token defines its level, a sort of priorization. Tokens covered completely by a token of a higher level are not part of the output and for ordinal position assignments. We use the possibiliy to supersede rules. In our example we define a hierarchy <b>SENT</b> (end of sentence) &lt; <b>ABBREV</b> (abbreviation) &lt; <b>URL</b> &lt; <b>EMAIL</b>. It means that a dot is an end of sentence marker if not part of an abbreviation, URL or email address. An abbreviation is not recognized as such, if part of an URL. An URL is not an URL, if part of an email address, etc.
	<br/>The declarations with an identifier followed by a '=' specify the patterns defined on tokens with the ordinal position as position reference for proximity range specifications.
	</p>
	<pre>
WORD ^1		:/\b\w+\b/;
SENT ^2		:/[.]/;
ABBREV ^3	: /\b[aA]bbr[\.]/ | /\b[aA]d[cjv][\.]/ | /\b[oO]bj[\.]/ | /\b[pP]seud[\.]/
		|  /\b[tT]rans[\.]/ | /\b[A-Za-z][\.][a-z][\.]/ | /\betc[\.]/ | /\bca[\.]/
		| /\b[mM]rs[\.]/ | /\b[pP]rof[\.]/ | /\b[rR]ev[\.]/ | /\b[hH]on[\.]/ | /\b[hH]rs[\.]/
		| /\b[A-Za-z][btlsr][\.]/ | /\b[gG]en[\.]/ | /\b[sS]ing[\.]/ | /\b[sS]yn[\.]/
		| /\b[aA]ve[\.]/ | /\b[d]dD]ept[\.]/ | /\b[eE]st[\.]/ | /\b[fF]ig[\.]/ | /\b[iI]nc[\.]/
		| /\b[oO]z[\.]/ | /\b[nN]o[\.]/ | /\b[sS]q[\.]/ | /\b[aA]ssn[\.]/ | /\b[tT]rans[\.]/
		| /\b[A-Z][\.]/
		;
ABBREV ^4	: /\bet\sal[\.]/ | /\b[rR][\.][iI][\.][pP]\b/;
URL ^5		: @([^\s/?\.#-][^\s/?\.#-]+\.)(aero|asia|biz|cat|com|coop|edu|gov|info|int|jobs|mil|mobi|museum|name|net|org|pro|tel|travel|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cx|cy|cz|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mn|mn|mo|mp|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|nom|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ra|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|xyz|ye|yt|yu|za|zm|zw|arpa)@;
URL ^6		: @\b(https?://|ftp://)?([^\s/?\.#-]+\.)([^\s/?\.#-]+\.)([a-z]{2,6})(/[^\s]*)?@;
EMAIL ^7	: /\b([a-z0-9_\.-]+)@([\da-z\.-]+)\.([a-z\.]{2,6})\b/;
CAPWORD ^1	: /\b\p{Lu}\p{Ll}*\b/;
LOWORD ^1	: /\b\p{Ll}+\b/;

Name		= sequence_imm( firstname=[0.75]CAPWORD, surname=CAPWORD | 2 );
Name		= sequence_imm( firstname=[0.75]CAPWORD, surname=ABBREV | 2 );
Name		= sequence_imm( Name, surname=CAPWORD | 10 );
Contact		= sequence_struct( SENT, Name, email=EMAIL | 10 );
	</pre>
	<p id="description">
	A "Name" is defined as a sequence of two words with capitalized first letter in a proximity distance of 2 (ordinal position distance, number of tokens)
	In this example the variable assignment of firstname gets the weight 0.75 assigned. Weigths are currently not
	interpreted or used by <i>StrusStream</i>. They are there for the user if part or the interpretation of the result.
	<br/>
	A "PersonMail" is defined as sequence of a name as we defined it and an email address in in a proximity
	distance of maximum 10 tokens, without an end of sentence marker appearing in between a candidate match.
	</p>
	<h4>Define the patterns in C++</h4>
	<p id="description"><font color=red>No documentation available yet.</font></p>
	<h4>Define the patterns in Python</h4>
	<p id="description"><font color=red>Python bindings not available yet.</font></p>

	<h3>Example input</h3>
	<pre>
&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;
&lt;doc&gt;
&lt;text&gt;This is an example document about Prof. John P. Doe, contact mail@etc.com, or visit www.etc.ch.
He is responsible for development, etc..
&lt;/text&gt;
&lt;/doc&gt;
	</pre>
	<h3>Tokenization</h3>
	<p id="description">We call the program <i>strusPatternMatch</i> with the following command line:
	<pre>
strusPatternMatch -K -p examples/config/program1.rul examples/data/input.xml
	</pre>
	</p>
	<p id="description">The option -K tells the program also to print the tokens recognized.
	The following output shows the tokens recognized with our set of patterns defined:
	</p>
	<pre>
1: WORD This
1: CAPWORD This
2: WORD is
2: LOWORD is
3: WORD an
3: LOWORD an
4: WORD example
4: LOWORD example
5: WORD document
5: LOWORD document
6: WORD about
6: LOWORD about
7: ABBREV Prof.
8: WORD John
8: CAPWORD John
9: ABBREV P.
10: WORD Doe
10: CAPWORD Doe
11: WORD contact
11: LOWORD contact
12: EMAIL mail@etc.com
13: WORD or
13: LOWORD or
14: WORD visit
14: LOWORD visit
15: URL www.etc.ch
16: SENT .
17: WORD He
17: CAPWORD He
18: WORD is
18: LOWORD is
19: WORD responsible
19: LOWORD responsible
20: WORD for
20: LOWORD for
21: WORD development
21: LOWORD development
22: ABBREV etc.
23: SENT .
	</pre>
	<h3>Rule matching</h3>
	<p id="description">As output of our command line call we get also the entities recognized with our example patterns:
	</p>
	<pre>
examples/data/input.xml:
Name [8, 108]: surname [9, 113, 2] 'P.' firstname [8, 108, 4] 'John'
Name [8, 108]: surname [10, 116, 3] 'Doe' firstname [8, 108, 4] 'John' surname [9, 113, 2] 'P.'
Contact [8, 108]: email [12, 129, 12] 'mail@etc.com' firstname [8, 108, 4] 'John' surname [9, 113, 2] 'P.'
Contact [8, 108]: email [12, 129, 12] 'mail@etc.com' surname [9, 113, 2] 'P.' firstname [8, 108, 4] 'John' surname [10, 116, 3] 'Doe'
OK done
	</pre>

	<h2>Performance measurements on an Intel NUC (NUC6i3SYK)</h2>
	<p id="description">The following runs show the behaviour of the <i>StrusStream</i> pattern matching without tokenization. We just use random documents represented as <a href="http://mathworld.wolfram.com/ZipfDistribution.html">Zipf distributed</a> random numbers, assuming 30'000 different terms in the whole collection. Each document contains 1000 such terms.
	The patterns are sequences of two random terms (<i>Zipf distribution</i> applied here too) within a proximity range of 1 to 10 with smaller proximity being much more likely than larger proximity conditions.
	We start 4 threads with the same pattern set with different input documents and test with 10 to 10'000'000 patterns evaluated.
	<br/><br/>
	This test does not help to estimate the performance of the system solving a real world problems. But it can help to estimate its behaviour when confronted with real world problems, if you look at the numbers in detail, like how many patterns were activated or how many patterns matched, etc.. Leaving the regular expression matching out in this test is not a problem since you can for sure assume, that the ultra fast <i>hyperscan</i> library from Intel will not be a bottleneck.
	For real world problems, you also have to take into account, that patterns get more complicated, with subexpressions, more complex operators than a simple sequence and variables assigned for items, you want to be part of the result. The numbers here are just representing the numbers for a set of the simplest type of pattern possible. If you measure the performance for pattern nodes detecting sequences of terms or subexpressions within the same sentence sentence, you will roughly double the execution time. Same for nodes detecting the appearance of two features in whatever order compared with a simple sequence.
	If you have more complex patterns, e.g. expression trees with many nodes, you have to count every node as unit and you have to take into account that every sub expression matched produces an event that gets part of the input processed.
	<br/><br/>
	The tests were run on an <i>Intel NUC</i> (<a href="http://www.intel.com/content/www/us/en/nuc/nuc-kit-nuc6i3syk.html">NUC6i3SYK</a>), a system with <b>4 GB RAM</b> is enough for processing the test with <b>10'000'000</b> nodes.
	<br/><br/>
	</p>
	<pre>
for dd in 10 100 1000 10000 100000 1000000 10000000; do
src/testRandomTokenPatternMatch -t 4 -o 30000 25 1000 $dd sequence; done

starting 4 threads for rule evaluation ...
OK
processed 10 patterns on 100 documents with total 0 matches in 185 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 491
	nofTriggersAvgActive: 0
	nofSignalsFired: 491

starting 4 threads for rule evaluation ...
OK
processed 100 patterns on 100 documents with total 17 matches in 188 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 0
	nofProgramsInstalled: 33967
	nofTriggersAvgActive: 1
	nofSignalsFired: 33984

starting 4 threads for rule evaluation ...
OK
processed 1000 patterns on 100 documents with total 6153 matches in 198 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 2035
	nofProgramsInstalled: 169880
	nofTriggersAvgActive: 6
	nofSignalsFired: 174716

starting 4 threads for rule evaluation ...
OK
processed 10000 patterns on 100 documents with total 55236 matches in 306 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 30437
	nofProgramsInstalled: 1987366
	nofTriggersAvgActive: 84
	nofSignalsFired: 2023920

starting 4 threads for rule evaluation ...
OK
processed 100000 patterns on 100 documents with total 655431 matches in 2418 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 360835
	nofProgramsInstalled: 20092579
	nofTriggersAvgActive: 848
	nofSignalsFired: 20545764

starting 4 threads for rule evaluation ...
OK
processed 1000000 patterns on 100 documents with total 6277057 matches in 55087 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 4194327
	nofProgramsInstalled: 198949620
	nofTriggersAvgActive: 8465
	nofSignalsFired: 202923433

starting 4 threads for rule evaluation ...
OK
processed 10000000 patterns on 100 documents with total 61650742 matches in 844535 milliseconds
statistiscs:
	nofAltKeyProgramsInstalled: 42381393
	nofProgramsInstalled: 1990633664
	nofTriggersAvgActive: 84649
	nofSignalsFired: 2028410811
	</pre>

<h4>Interpretation</h4>
<p id="description">
<ol>
<li>processed <b>N</b> patterns on 100 documents with total <b>X</b> matches in <b>T</b> milliseconds:
<ul>
<li><b>N</b>: Number of patterns, sequences of two tokens in a ordinal position distance of 1 to 10 (possibly with unspecified tokens appearing in between) defined</li>
<li><b>X</b>: Total number of matching token sequences in 100 documents</li>
<li><b>T</b>: Execution time for processing all 100 documents</li>
</ul>
<li><b>nofAltKeyProgramsInstalled</b>: Tells how many optimized patterns with an alternative key event were triggered for execution by a key event during the whole processing of the 100 documents. A pattern is optimized, if an initial token, triggering the evaluation of the pattern, is statistically appearing too often. In this case a valable alternative token, if it exists, is chosen, and the initial token event is replayed for the pattern to match. The intention of this optimization is to reduce the number or hits and the following processing of rules that may not match. As example consider a rule like "The world", that is triggered with every appearance of "the". Triggering the rule with "world" is better in english text.</li>
<li><b>nofProgramsInstalled</b>: Tells how many patterns were triggered for execution by a key event during the whole processing of the 100 documents.</li>
<li><b>nofTriggersAvgActive</b>: Tells how many patterns were active (waiting for events to complete the pattern match) in average for every input token processed.</li>
<li><b>nofSignalsFired</b>: Tells how many signals were fired during the whole processing of the 100 documents. An active pattern listens for signals fired on a slot. The pattern matches on a completion condition on the slot.</li>
</ol>
</p>
<h4>Performance measurement plot</h4>
<p id="description">The following plot shows the measured execution time against the number of sequence 
rule nodes evaluated.
</p>
<img src="perfplot.png" width="500" alt="performance plot" />

<h2>Open problems and bugs</h2>
<h4>within and within_struct greediness</h4>
<p id="description">
Patterns with the operator <b>within</b> or <b>within_struct</b> currently do not work correctly, if
accepted sets of subexpressions are not disjunct. This is due to the greediness of the algorithm,
that does not follow alternative paths or backtrack. To illustrate the problem, have a look at the
pattern matching the elements "(A B)" and "A" in any order and the source "ABA". The current situation
is that the pattern matcher recognizes "A" as "A" and does not accept a signal for "AB" anymore at the
same position for this pattern.
<br/>
There are straightforward solutions to this problem, but we did not find yet a good one.
We are aware of this problem and we know that it cannot be neglected.
Currently you have to formulate your 'within' rules as all possible permutations of sequences
(2 patterns "((A B) A)" and "(A (A B))", if you have 'within' rules with non disjunct accepted sets.
Sequences do not have this problem.
</p>
<h4>Symbols and identifiers</h4>
<p id="description">It does not make sense to implement every symbol or identifier as item in
the regular expression automaton. For representing ordinary words, we need the possibility
to declare identifiers in our rule language. The <a href="http://patrickfrey.github.io/strusStream/doc/doxygen/html/classstrus_1_1CharRegexMatchInstanceInterface.html">CharRegexMatchInstanceInterface</a>
already has a method to declare such a symbol with the method <i>defineSymbol</i>. 
But this is one feature not tested yet and not available in our example language.
</p>


<h2>Testing</h2>
<p id="description">We tested the token pattern matching of <i>StrusStream</i> with random generated
rules on random generated documents verified with an alternative implementation.
The test program can be run manually
<pre>
cd tests/randomExpressionTreeMatch
src/testRandomExpressionTreeMatch 100 100 100 100 ./
</pre>
And the differences can be inspected with a diff of the res.txt with the exp.txt file.
Currently the tests fail because of small differences due to the problems with operators on subexpressions with 
non disjuct sets of accepted input. We are working on the problem.
</pre>
</p>

<h2>Caveats</h2>
<p id="description"><i>StrusStream</i> handles events immediately when they are seen.
This can lead to anomalies, when formulating restrictions, e.g. with 'sequence_struct' or 'within_struct'
in cases the structure delimiter gets the same ordinal position assigned than another token that is part of the
pattern. When the last element of a rule is detected without passing over a structure element, that is part of 
the restriction condition, then the result is emitted, even if a restriction event with the same ordinal position,
that should overrule the decision, happens thereafter. Another anomaly of this kind can happen, when the 
restricting element of a rule occurrs with the same position, but before the key event triggering the pattern.
<br/>
Practically we do not see too bad consequences of this behaviour, because structure delimiters usually get their
own ordinal position assigned. But it might be needed in the future to treat these cases differently.
<br/>
At the moment we just premention the expected behaviour.
</p>

<h2>Resume</h2>
<p id="description"><i>StrusStream</i> provides token pattern matching in a competitive performance for
matching large sets of patterns. <br/>
The implementation is maybe not optimal in numbers of reads and writes of memory and in 
numbers of branching instructions, but it is software with a good flow. It has
simple operations mainly operating on local (near, on chip) memory, able to use SIMD capabilities
of modern CPUs and it accesses new (far away) memory mainly for feeding the system.
<br/>
For users that do not need arbitrary programs to define patterns and for users, that can live with 
the restrictions of the model of <i>StrusStream</i>, the prospect of the performance may be convincing.
</p>
</div>
</div>
</body>
</html>

